{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fff181c0",
   "metadata": {},
   "source": [
    "# VRS Bench Inference with Rex-Omni API (Async & Multi-Object)\n",
    "\n",
    "This notebook runs inference on the `vrsbench_val_data.parquet` dataset using the **Rex-Omni** HTTP API.\n",
    "\n",
    "**Key Features:**\n",
    "- **Multi-Object Splitting**: Each referring sentence in an image is treated as a separate sample.\n",
    "- **Async Inference**: Uses `aiohttp` and `asyncio` for concurrent requests.\n",
    "- **Concurrency Control**: Limits concurrent requests to 5.\n",
    "- **Sample Limit**: Runs on the first 1000 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c133d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install aiohttp nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6199055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import base64\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import nest_asyncio\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops in Jupyter\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dfbd8d",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a95d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rex-Omni API Endpoint\n",
    "API_URL = \"https://animeshraj958--rex-vision-service-api-grounding.modal.run\"\n",
    "\n",
    "# Dataset\n",
    "PARQUET_FILE = \"vrsbench_val_data.parquet\"\n",
    "OUTPUT_FILE = \"vrs_inference_results_async.json\"\n",
    "\n",
    "# Limits\n",
    "MAX_SAMPLES = 1000\n",
    "CONCURRENCY = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4588a7e5",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa651375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_process_data(parquet_file, limit=None, base_dir='.'):\n",
    "    \"\"\"\n",
    "    Robust loader with logging for missing images / malformed rows.\n",
    "\n",
    "    - base_dir: attempt to resolve relative image paths under this directory.\n",
    "    \"\"\"\n",
    "    print(f\"Loading {parquet_file} ...\")\n",
    "    if not os.path.exists(parquet_file):\n",
    "        raise FileNotFoundError(f\"Parquet file not found: {parquet_file}\")\n",
    "\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    print(f\"Parquet rows: {len(df)}\")\n",
    "\n",
    "    samples = []\n",
    "    skipped = {\n",
    "        \"missing_image\": 0,\n",
    "        \"bad_objects\": 0,\n",
    "        \"bad_object_entry\": 0,\n",
    "    }\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        image_path = row.get('image_path') or row.get('image') or None\n",
    "        image_id = row.get('image_id') or row.get('id') or f\"row_{idx}\"\n",
    "\n",
    "        if not image_path:\n",
    "            # no image path -> skip\n",
    "            skipped[\"missing_image\"] += 1\n",
    "            continue\n",
    "\n",
    "        # try absolute first, then join with base_dir\n",
    "        if not os.path.exists(image_path):\n",
    "            candidate = os.path.join(base_dir, image_path)\n",
    "            if os.path.exists(candidate):\n",
    "                image_path = candidate\n",
    "            else:\n",
    "                # try basename in base_dir\n",
    "                bn = os.path.basename(image_path)\n",
    "                candidate2 = os.path.join(base_dir, bn)\n",
    "                if os.path.exists(candidate2):\n",
    "                    image_path = candidate2\n",
    "                else:\n",
    "                    # missing\n",
    "                    skipped[\"missing_image\"] += 1\n",
    "                    continue\n",
    "\n",
    "        # get objects field\n",
    "        objects = row.get('objects', None)\n",
    "        if objects is None:\n",
    "            # try other probable column names\n",
    "            for alt in ['instances', 'annotations', 'objs']:\n",
    "                if alt in row:\n",
    "                    objects = row.get(alt)\n",
    "                    break\n",
    "\n",
    "        # if string, try parse JSON\n",
    "        if isinstance(objects, str):\n",
    "            try:\n",
    "                objects = json.loads(objects)\n",
    "            except Exception as e:\n",
    "                skipped[\"bad_objects\"] += 1\n",
    "                continue\n",
    "\n",
    "        if not isinstance(objects, list):\n",
    "            skipped[\"bad_objects\"] += 1\n",
    "            continue\n",
    "\n",
    "        for obj in objects:\n",
    "            if not isinstance(obj, dict):\n",
    "                skipped[\"bad_object_entry\"] += 1\n",
    "                continue\n",
    "\n",
    "            # try common keys for referring sentence and bbox\n",
    "            caption = obj.get('referring_sentence') or obj.get('caption') or obj.get('sentence') or \"\"\n",
    "            bbox = obj.get('obj_coord') or obj.get('bbox') or obj.get('box') or obj.get('coords') or []\n",
    "\n",
    "            samples.append({\n",
    "                \"image_id\": image_id,\n",
    "                \"image_path\": image_path,\n",
    "                \"caption\": caption,\n",
    "                \"ground_truth_bbox\": bbox,\n",
    "                \"obj_id\": obj.get('obj_id') or obj.get('id')\n",
    "            })\n",
    "\n",
    "            if limit and len(samples) >= limit:\n",
    "                print(\"Reached limit:\", limit)\n",
    "                print(\"Skipped summary:\", skipped)\n",
    "                return samples\n",
    "\n",
    "    print(\"Finished. samples:\", len(samples))\n",
    "    print(\"Skipped summary:\", skipped)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179ed9c9",
   "metadata": {},
   "source": [
    "## 3. Async Inference Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f726cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def encode_image(image_path):\n",
    "    \"\"\"Reads image and converts to base64 (blocking I/O run in executor).\"\"\"\n",
    "    loop = asyncio.get_event_loop()\n",
    "    def _read():\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as f:\n",
    "                data = f.read()\n",
    "                encoded = base64.b64encode(data).decode('utf-8')\n",
    "                # Determine mime type\n",
    "                mime = \"image/png\" if image_path.lower().endswith(\".png\") else \"image/jpeg\"\n",
    "                return f\"data:{mime};base64,{encoded}\"\n",
    "        except Exception as e:\n",
    "            return None\n",
    "    return await loop.run_in_executor(None, _read)\n",
    "\n",
    "async def process_sample(session, sample, semaphore):\n",
    "    \"\"\"Process a single sample with concurrency limit.\"\"\"\n",
    "    async with semaphore:\n",
    "        image_path = sample['image_path']\n",
    "        caption = sample['caption']\n",
    "        \n",
    "        # Encode image\n",
    "        image_data = await encode_image(image_path)\n",
    "        if not image_data:\n",
    "            return {**sample, \"error\": \"Image read failed\"}\n",
    "            \n",
    "        payload = {\n",
    "            \"image\": image_data,\n",
    "            \"caption\": caption\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            async with session.post(API_URL, json=payload) as response:\n",
    "                if response.status == 200:\n",
    "                    result = await response.json()\n",
    "                    return {**sample, \"prediction\": result}\n",
    "                else:\n",
    "                    text = await response.text()\n",
    "                    return {**sample, \"error\": f\"API {response.status}: {text}\"}\n",
    "        except Exception as e:\n",
    "            return {**sample, \"error\": str(e)}\n",
    "\n",
    "async def run_async_inference(samples, concurrency=5):\n",
    "    semaphore = asyncio.Semaphore(concurrency)\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [\n",
    "            process_sample(session, sample, semaphore)\n",
    "            for sample in samples\n",
    "        ]\n",
    "        \n",
    "        results = []\n",
    "        # Use tqdm for progress bar\n",
    "        for f in tqdm(asyncio.as_completed(tasks), total=len(tasks), desc=\"Async Inference\"):\n",
    "            result = await f\n",
    "            results.append(result)\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844fd9c7",
   "metadata": {},
   "source": [
    "## 4. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fda309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the async loop\n",
    "results = asyncio.run(run_async_inference(all_samples, concurrency=CONCURRENCY))\n",
    "\n",
    "# Save results\n",
    "with open(OUTPUT_FILE, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "    \n",
    "print(f\"Saved {len(results)} results to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c711e44",
   "metadata": {},
   "source": [
    "## 5. Visualize a Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a083ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_result(image_input, result, caption):\n",
    "    \"\"\"Helper to draw bounding boxes on the image\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_input).convert(\"RGB\")\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(img)\n",
    "        ax = plt.gca()\n",
    "        plt.title(f\"Caption: {caption}\")\n",
    "        \n",
    "        # Draw boxes from Rex-Omni annotations\n",
    "        if result and \"annotations\" in result:\n",
    "            for ann in result.get(\"annotations\", []):\n",
    "                phrase = ann.get(\"phrase\", \"object\")\n",
    "                boxes = ann.get(\"boxes\", [])\n",
    "                \n",
    "                for bbox in boxes:\n",
    "                    # bbox is [x1, y1, x2, y2]\n",
    "                    width = bbox[2] - bbox[0]\n",
    "                    height = bbox[3] - bbox[1]\n",
    "                    \n",
    "                    rect = patches.Rectangle(\n",
    "                        (bbox[0], bbox[1]), width, height, \n",
    "                        linewidth=2, edgecolor='#00FF00', facecolor='none'\n",
    "                    )\n",
    "                    ax.add_patch(rect)\n",
    "                    \n",
    "                    plt.text(\n",
    "                        bbox[0], bbox[1] - 5, phrase, \n",
    "                        color='black', fontsize=10, weight='bold',\n",
    "                        bbox=dict(facecolor='#00FF00', alpha=0.7, edgecolor='none', pad=2)\n",
    "                    )\n",
    "            \n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Visualization error: {e}\")\n",
    "\n",
    "# Visualize the first successful result\n",
    "for res in results:\n",
    "    if \"prediction\" in res and res[\"prediction\"].get(\"success\", False):\n",
    "        visualize_result(res['image_path'], res['prediction'], res['caption'])\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
